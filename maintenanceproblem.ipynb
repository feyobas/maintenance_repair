{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bf527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri yükleniyor...\n",
      "Veri ön işleniyor...\n",
      "Zaman serisi özellikleri ekleniyor...\n",
      "Yüksek korelasyonlu özellikler eleniyor...\n",
      "Elenen özellikler: []\n",
      "Kalan özellikler: ['volt', 'rotate', 'pressure', 'vibration', 'volt_lag_1', 'volt_lag_2', 'rotate_lag_1', 'rotate_lag_2', 'pressure_lag_1', 'pressure_lag_2', 'vibration_lag_1', 'vibration_lag_2', 'volt_ma_3', 'rotate_ma_3', 'pressure_ma_3', 'vibration_ma_3', 'volt_std_3', 'rotate_std_3', 'pressure_std_3', 'vibration_std_3', 'volt_diff', 'rotate_diff', 'pressure_diff', 'vibration_diff']\n",
      "Model hazırlanıyor...\n",
      "SMOTE uygulanıyor... (Veri boyutu: 30000)\n",
      "Logistic Regression, Random Forest, CatBoost ve XGBoost modelleri eğitiliyor...\n",
      "\n",
      "➡️ Logistic Regression modeli eğitiliyor...\n",
      "🔎 Logistic Regression için SHAP değerleri hesaplanıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FEYYAZ\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2b72a6093742a7b734c973b4de4098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP başarıyla tamamlandı - Logistic Regression\n",
      "\n",
      "➡️ Random Forest modeli eğitiliyor...\n",
      "🔎 Random Forest için SHAP değerleri hesaplanıyor...\n",
      "✅ SHAP başarıyla tamamlandı - Random Forest\n",
      "\n",
      "➡️ CatBoost modeli eğitiliyor...\n",
      "🔎 CatBoost için SHAP değerleri hesaplanıyor...\n",
      "✅ SHAP başarıyla tamamlandı - CatBoost\n",
      "\n",
      "➡️ XGBoost modeli eğitiliyor...\n",
      "🔎 XGBoost için SHAP değerleri hesaplanıyor...\n",
      "✅ SHAP başarıyla tamamlandı - XGBoost\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier  \n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import time\n",
    "import datetime\n",
    "import subprocess\n",
    "import platform\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Başlangıç zamanı kaydı\n",
    "start_time = time.time()\n",
    "\n",
    "# -------------------- TKINTER ARAYÜZÜ --------------------\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "try:\n",
    "    data_fraction = float(simpledialog.askstring(\"Veri Yüzdesi\", \"Analiz için veri yüzdesini girin (0.0 - 1.0):\", initialvalue=\"0.015\"))\n",
    "    if not (0 < data_fraction <= 1):\n",
    "        raise ValueError(\"Geçersiz oran\")\n",
    "except:\n",
    "    messagebox.showerror(\"Hata\", \"Geçerli bir oran girilmedi. Program sonlandırılıyor.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    epochs = int(simpledialog.askstring(\"Epoch Sayısı\", \"LSTM Autoencoder için epoch sayısını girin:\", initialvalue=\"15\"))\n",
    "except:\n",
    "    messagebox.showerror(\"Hata\", \"Geçerli bir epoch sayısı girilmedi. Program sonlandırılıyor.\")\n",
    "    exit()\n",
    "\n",
    "# -------------------- DOSYA YOLLARI --------------------\n",
    "telemetry_path = r\"C:\\Users\\FEYYAZ\\Desktop\\PdM_telemetry.csv\"\n",
    "failures_path = r\"C:\\Users\\FEYYAZ\\Desktop\\PdM_failures.csv\"\n",
    "\n",
    "# Rapor için benzersiz dosya adı oluşturma\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_filename = f\"model_comparison_report_{timestamp}.pdf\"\n",
    "\n",
    "# -------------------- VERİ YÜKLEME --------------------\n",
    "print(\"Veri yükleniyor...\")\n",
    "try:\n",
    "    telemetry = pd.read_csv(telemetry_path)\n",
    "    failures = pd.read_csv(failures_path)\n",
    "    telemetry['datetime'] = pd.to_datetime(telemetry['datetime'])\n",
    "    failures['datetime'] = pd.to_datetime(failures['datetime'])\n",
    "except Exception as e:\n",
    "    messagebox.showerror(\"Hata\", f\"Veri dosyaları yüklenemedi: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# -------------------- VERİ ÖN İŞLEME --------------------\n",
    "print(\"Veri ön işleniyor...\")\n",
    "telemetry_sampled = telemetry.sample(frac=data_fraction, random_state=42)\n",
    "telemetry_hourly = telemetry_sampled.groupby(['machineID', pd.Grouper(key='datetime', freq='h')]).mean().reset_index()\n",
    "telemetry_hourly['failure'] = 0\n",
    "\n",
    "# Başarısızlıkları işaretleme\n",
    "for _, row in failures.iterrows():\n",
    "    mask = (\n",
    "        (telemetry_hourly['machineID'] == row['machineID']) &\n",
    "        (telemetry_hourly['datetime'] == row['datetime'])\n",
    "    )\n",
    "    telemetry_hourly.loc[mask, 'failure'] = 1\n",
    "\n",
    "# -------------------- ZAMAN SERİSİ ÖZELLİK MÜHENDİSLİĞİ --------------------\n",
    "print(\"Zaman serisi özellikleri ekleniyor...\")\n",
    "def add_time_series_features(df, features, lag_steps=2, window_size=3):\n",
    "    df = df.sort_values(['machineID', 'datetime']).copy()\n",
    "    for feature in features:\n",
    "        for lag in range(1, lag_steps + 1):\n",
    "            df[f'{feature}_lag_{lag}'] = df.groupby('machineID')[feature].shift(lag)\n",
    "        df[f'{feature}_ma_{window_size}'] = df.groupby('machineID')[feature].rolling(window=window_size).mean().reset_index(level=0, drop=True)\n",
    "        df[f'{feature}_std_{window_size}'] = df.groupby('machineID')[feature].rolling(window=window_size).std().reset_index(level=0, drop=True)\n",
    "        df[f'{feature}_diff'] = df.groupby('machineID')[feature].diff()\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "base_features = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "telemetry_hourly = add_time_series_features(telemetry_hourly, base_features, lag_steps=2, window_size=3)\n",
    "\n",
    "# Yeni özellik listesi\n",
    "features = base_features + [\n",
    "    f'{feat}_lag_{lag}' for feat in base_features for lag in range(1, 3)\n",
    "] + [\n",
    "    f'{feat}_ma_3' for feat in base_features\n",
    "] + [\n",
    "    f'{feat}_std_3' for feat in base_features\n",
    "] + [\n",
    "    f'{feat}_diff' for feat in base_features\n",
    "]\n",
    "\n",
    "# -------------------- ÖZELLİK SEÇİMİ (KORELASYON ANALİZİ) --------------------\n",
    "print(\"Yüksek korelasyonlu özellikler eleniyor...\")\n",
    "X_temp = telemetry_hourly[features]\n",
    "corr_matrix = X_temp.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "print(f\"Elenen özellikler: {to_drop}\")\n",
    "features = [f for f in features if f not in to_drop]\n",
    "print(f\"Kalan özellikler: {features}\")\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "print(\"Model hazırlanıyor...\")\n",
    "X = telemetry_hourly[features]\n",
    "y = telemetry_hourly['failure']\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "max_samples = min(len(X_scaled), 30000)\n",
    "X_scaled_limited = X_scaled[:max_samples]\n",
    "y_limited = y[:max_samples]\n",
    "\n",
    "print(f\"SMOTE uygulanıyor... (Veri boyutu: {len(X_scaled_limited)})\")\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled_limited, y_limited)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test, columns=features)\n",
    "\n",
    "# -------------------- DÖRT MODELİ DE EĞİTME --------------------\n",
    "print(\"Logistic Regression, Random Forest, CatBoost ve XGBoost modelleri eğitiliyor...\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        C=0.01,\n",
    "        solver='liblinear'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        min_samples_split=30,\n",
    "        min_samples_leaf=15,\n",
    "        max_features='sqrt',\n",
    "        max_samples=0.7,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=50,\n",
    "        depth=2,\n",
    "        l2_leaf_reg=50,\n",
    "        subsample=0.6,\n",
    "        bagging_temperature=1.5,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=80,\n",
    "        max_depth=2,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.5,\n",
    "        min_child_weight=20,\n",
    "        reg_alpha=2.0,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "shap_values_dict = {}\n",
    "y_pred_dict = {}\n",
    "y_proba_dict = {}\n",
    "xgboost_model = None\n",
    "xgboost_best_iteration = 100\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n➡️ {name} modeli eğitiliyor...\")\n",
    "    if name == 'XGBoost':\n",
    "        params = {\n",
    "            'max_depth': 2,\n",
    "            'learning_rate': 0.007,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'min_child_weight': 20,\n",
    "            'reg_lambda': 100,\n",
    "            'reg_alpha': 10.0,\n",
    "            'gamma': 10,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "        evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=300,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=30,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        xgboost_model = bst\n",
    "        xgboost_best_iteration = bst.best_iteration + 1\n",
    "        y_pred = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        y_proba = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    results[name] = {\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "    y_pred_dict[name] = y_pred\n",
    "    y_proba_dict[name] = y_proba\n",
    "    print(f\"🔎 {name} için SHAP değerleri hesaplanıyor...\")\n",
    "    sample_size = min(100, len(X_test_df))\n",
    "    X_test_sample = X_test_df.iloc[:sample_size]\n",
    "    try:\n",
    "        if name == \"XGBoost\":\n",
    "            explainer = shap.TreeExplainer(xgboost_model)\n",
    "            shap_vals = explainer.shap_values(X_test_sample)\n",
    "            shap_values_dict[name] = shap_vals\n",
    "        elif name in [\"Random Forest\", \"CatBoost\"]:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_vals = explainer.shap_values(X_test_sample)\n",
    "            shap_values_dict[name] = shap_vals[1] if isinstance(shap_vals, list) else shap_vals\n",
    "        else:\n",
    "            background = shap.kmeans(X_train, 10)\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, background)\n",
    "            shap_values_dict[name] = explainer.shap_values(X_test_sample)[1]\n",
    "        print(f\"✅ SHAP başarıyla tamamlandı - {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ SHAP hesaplanamadı - {name}: {str(e)}\")\n",
    "        shap_values_dict[name] = None\n",
    "\n",
    "# -------------------- ÖĞRENME EĞRİSİ GÖRSELİ --------------------\n",
    "def plot_learning_curve(model, X, y, model_name, cv=5, scoring='f1'):\n",
    "    try:\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    "            train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    "        )\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        test_mean = np.mean(test_scores, axis=1)\n",
    "        test_std = np.std(test_scores, axis=1)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_sizes, train_mean, 'o-', color='r', label='Eğitim Skoru')\n",
    "        plt.plot(train_sizes, test_mean, 'o-', color='g', label='Doğrulama Skoru')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\n",
    "        plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\n",
    "        plt.title(f\"{model_name} Öğrenme Eğrisi\")\n",
    "        plt.xlabel(\"Eğitim Örnek Sayısı\")\n",
    "        plt.ylabel(\"F1 Skoru\")\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        filename = f\"learning_curve_{model_name.replace(' ', '_').lower()}.png\"\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Öğrenme eğrisi oluşturulamadı - {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "rf_path = plot_learning_curve(models['Random Forest'], X_resampled, y_resampled, \"Random Forest\")\n",
    "cb_path = plot_learning_curve(models['CatBoost'], X_resampled, y_resampled, \"CatBoost\")\n",
    "# For XGBoost, create a temporary XGBClassifier for learning curve\n",
    "xgb_temp = XGBClassifier(\n",
    "  \n",
    "\n",
    ")\n",
    "xgb_path = plot_learning_curve(xgb_temp, X_resampled, y_resampled, \"XGBoost\")\n",
    "print(f\"Öğrenme eğrisi görselleri oluşturuldu:\\n- {rf_path}\\n- {cb_path}\\n- {xgb_path}\")\n",
    "\n",
    "# -------------------- KARŞILAŞTIRMA GÖRSELLEŞTİRMELERİ --------------------\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1 Score', 'AUC'],\n",
    "    'Logistic Regression': [results['Logistic Regression']['Precision'], \n",
    "                          results['Logistic Regression']['Recall'],\n",
    "                          results['Logistic Regression']['F1 Score'],\n",
    "                          results['Logistic Regression']['AUC']],\n",
    "    'Random Forest': [results['Random Forest']['Precision'], \n",
    "                    results['Random Forest']['Recall'],\n",
    "                    results['Random Forest']['F1 Score'],\n",
    "                    results['Random Forest']['AUC']],\n",
    "    'CatBoost': [results['CatBoost']['Precision'], \n",
    "                results['CatBoost']['Recall'],\n",
    "                results['CatBoost']['F1 Score'],\n",
    "                results['CatBoost']['AUC']],\n",
    "    'XGBoost': [results['XGBoost']['Precision'], \n",
    "                results['XGBoost']['Recall'],\n",
    "                results['XGBoost']['F1 Score'],\n",
    "                results['XGBoost']['AUC']]\n",
    "})\n",
    "\n",
    "print(\"\\n📋 Model Performans Karşılaştırması:\")\n",
    "print(metrics_table)\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for name, result in results.items():\n",
    "        plt.plot(result['fpr'], result['tpr'], lw=2, label=f\"{name} (AUC = {result['AUC']:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Eğrisi Karşılaştırması')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"roc_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"ROC eğrisi oluşturulamadı: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for i, (name, y_pred) in enumerate(y_pred_dict.items()):\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "        axes[i].set_title(f'Confusion Matrix - {name}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Confusion matrix oluşturulamadı: {str(e)}\")\n",
    "\n",
    "for name, shap_values in shap_values_dict.items():\n",
    "    if shap_values is not None:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=features, show=False, plot_size=(8, 5))\n",
    "            plt.title(f\"SHAP Summary - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_summary_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"SHAP summary plot oluşturulamadı - {name}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"SHAP summary plot atlandı - {name} için SHAP değerleri bulunamadı\")\n",
    "\n",
    "for name, shap_values in shap_values_dict.items():\n",
    "    if shap_values is not None:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.plots.waterfall(shap_values[0], max_display=10, show=False)\n",
    "            plt.title(f\"SHAP Waterfall Plot - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_waterfall_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"İlk waterfall plot oluşturulamadı - {name}: {str(e)}\")\n",
    "            try:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.plots.force(shap_values[0], show=False)\n",
    "                plt.title(f\"SHAP Force Plot - {name}\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"shap_force_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "                plt.close()\n",
    "                print(f\"Alternatif olarak Force Plot oluşturuldu - {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Force plot da oluşturulamadı - {name}: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, model_name in enumerate(['Random Forest', 'CatBoost', 'XGBoost']):\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        if model_name == 'XGBoost':\n",
    "            # Extract feature importance from Booster\n",
    "            importance = xgboost_model.get_score(importance_type='gain')\n",
    "            feature_names = features  # Use original feature names\n",
    "            importance_values = [importance.get(f, 0) for f in feature_names]\n",
    "            indices = np.argsort(importance_values)[::-1]\n",
    "            sorted_importances = [importance_values[i] for i in indices]\n",
    "            sorted_features = [feature_names[i] for i in indices]\n",
    "        else:\n",
    "            importances = models[model_name].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            sorted_importances = [importances[i] for i in indices]\n",
    "            sorted_features = [features[i] for i in indices]\n",
    "        sns.barplot(x=sorted_importances, y=sorted_features)\n",
    "        plt.title(f\"{model_name} Öznitelik Önemi\")\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(\"tree_models_feature_importance.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Öznitelik önemi karşılaştırması oluşturulamadı: {str(e)}\")\n",
    "\n",
    "for model_name in ['Random Forest', 'CatBoost', 'XGBoost']:\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        if model_name == 'XGBoost':\n",
    "            importance = xgboost_model.get_score(importance_type='gain')\n",
    "            feature_names = features\n",
    "            importance_values = [importance.get(f, 0) for f in feature_names]\n",
    "            indices = np.argsort(importance_values)[::-1]\n",
    "            sorted_importances = [importance_values[i] for i in indices]\n",
    "            sorted_features = [feature_names[i] for i in indices]\n",
    "        else:\n",
    "            importances = models[model_name].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            sorted_importances = [importances[i] for i in indices]\n",
    "            sorted_features = [features[i] for i in indices]\n",
    "        sns.barplot(x=sorted_importances, y=sorted_features)\n",
    "        plt.title(f\"{model_name} Öznitelik Önemi\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{model_name.lower().replace(' ', '_')}_feature_importance.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Öznitelik önemi plotu oluşturulamadı - {model_name}: {str(e)}\")\n",
    "\n",
    "print(\"t-SNE görselleştirmesi hazırlanıyor...\")\n",
    "try:\n",
    "    tsne_size = min(5000, len(X_scaled))\n",
    "    failure_indices = np.where(y[:tsne_size] == 1)[0]\n",
    "    non_failure_indices = np.where(y[:tsne_size] == 0)[0]\n",
    "    min_samples_per_class = min(len(failure_indices), len(non_failure_indices))\n",
    "    replace_sampling = min_samples_per_class < 50\n",
    "    sample_size = max(min(300, min_samples_per_class), 50)\n",
    "    \n",
    "    if len(failure_indices) > 0 and len(non_failure_indices) > 0:\n",
    "        sampled_failure_indices = np.random.choice(\n",
    "            failure_indices, \n",
    "            size=min(sample_size, len(failure_indices)), \n",
    "            replace=replace_sampling\n",
    "        )\n",
    "        sampled_non_failure_indices = np.random.choice(\n",
    "            non_failure_indices, \n",
    "            size=min(sample_size, len(non_failure_indices)), \n",
    "            replace=replace_sampling\n",
    "        )\n",
    "        combined_indices = np.concatenate([sampled_failure_indices, sampled_non_failure_indices])\n",
    "        X_for_tsne = X_scaled[combined_indices]\n",
    "        y_for_tsne = y.iloc[combined_indices]\n",
    "        perplexity_value = min(30, len(X_for_tsne) - 1)\n",
    "        perplexity_value = max(2, perplexity_value)\n",
    "        print(f\"t-SNE kullanılan örnek sayısı: {len(X_for_tsne)}, perplexity: {perplexity_value}\")\n",
    "        tsne = TSNE(\n",
    "            n_components=2, \n",
    "            perplexity=perplexity_value,\n",
    "            random_state=42,\n",
    "            learning_rate='auto',  \n",
    "            n_iter=1000\n",
    "        )\n",
    "        X_embedded = tsne.fit_transform(X_for_tsne)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], \n",
    "                          c=y_for_tsne, cmap='coolwarm', \n",
    "                          s=20, \n",
    "                          alpha=0.7)\n",
    "        plt.title(\"t-SNE Görselleştirmesi\", fontsize=14)\n",
    "        plt.xlabel(\"TSNE-1\", fontsize=12)\n",
    "        plt.ylabel(\"TSNE-2\", fontsize=12)\n",
    "        plt.colorbar(scatter, label='Failure')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tsne_plot.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(\"t-SNE görselleştirmesi başarıyla oluşturuldu.\")\n",
    "    else:\n",
    "        raise ValueError(\"Her iki sınıftan da yeterli örnek bulunamadı\")\n",
    "except Exception as e:\n",
    "    print(f\"t-SNE görselleştirmesi sırasında hata oluştu: {str(e)}\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.text(0.5, 0.5, f\"t-SNE görselleştirmesi oluşturulamadı\\nHata: {str(e)}\", \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"tsne_plot.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------- LSTM AUTOENCODER ANOMALİ TESPİTİ --------------------\n",
    "print(\"LSTM autoencoder hazırlanıyor...\")\n",
    "normal_data = telemetry_hourly[telemetry_hourly['failure'] == 0][features].values\n",
    "abnormal_data = telemetry_hourly[telemetry_hourly['failure'] == 1][features].values\n",
    "max_normal = min(8000, len(normal_data))\n",
    "normal_data = normal_data[:max_normal]\n",
    "scaler_lstm = MinMaxScaler()\n",
    "normal_scaled = scaler_lstm.fit_transform(normal_data)\n",
    "seq_length = 10\n",
    "X_seq = []\n",
    "for i in range(len(normal_scaled) - seq_length):\n",
    "    X_seq.append(normal_scaled[i:i+seq_length])\n",
    "X_seq = np.array(X_seq)\n",
    "print(f\"LSTM autoencoder eğitiliyor... (Epochs: {epochs})\")\n",
    "input_layer = Input(shape=(seq_length, X_seq.shape[2]))\n",
    "x = LSTM(8, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(4, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01))(x)\n",
    "x = RepeatVector(seq_length)(x)\n",
    "x = LSTM(4, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(8, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "output_layer = TimeDistributed(Dense(X_seq.shape[2]))(x)\n",
    "model_lstm = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "history = model_lstm.fit(\n",
    "    X_seq, X_seq, \n",
    "    epochs=epochs, \n",
    "    batch_size=64, \n",
    "    validation_split=0.1, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "X_pred = model_lstm.predict(X_seq)\n",
    "mse = np.mean(np.power(X_seq - X_pred, 2), axis=(1, 2))\n",
    "threshold = np.percentile(mse, 95)\n",
    "print(\"🔺 Anomali eşik değeri:\", threshold)\n",
    "try:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(mse, label='Reconstruction Error')\n",
    "    plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "    plt.title(\"LSTM Autoencoder Anomali Tespiti\", fontsize=14)\n",
    "    plt.xlabel(\"Dizi İndeksi\", fontsize=12)\n",
    "    plt.ylabel(\"Hata (MSE)\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"LSTM Autoencoder Eğitim Geçmişi\", fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"lstm_anomaly_plot.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"LSTM anomali plotu oluşturulamadı: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(mse, bins=50, alpha=0.7, color='blue')\n",
    "    plt.axvline(x=threshold, color='red', linestyle='--', \n",
    "                label=f'Anomali Eşiği ({threshold:.4f})')\n",
    "    plt.title(\"MSE Dağılımı ve Anomali Eşiği\", fontsize=14)\n",
    "    plt.xlabel(\"MSE Değeri\", fontsize=12)\n",
    "    plt.ylabel(\"Frekans\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mse_histogram.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"MSE histogramı oluşturulamadı: {str(e)}\")\n",
    "\n",
    "# -------------------- PDF RAPORU --------------------\n",
    "print(f\"📄 PDF raporu oluşturuluyor: {report_filename}\")\n",
    "training_times = {}\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    if name == 'XGBoost':\n",
    "        # Use xgboost.train for training time measurement\n",
    "        params = {\n",
    "            'max_depth': 3,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'min_child_weight': 5,\n",
    "            'reg_lambda': 30,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "        evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=500,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    training_times[name] = end - start\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    names = list(training_times.keys())\n",
    "    times = list(training_times.values())\n",
    "    sorted_indices = np.argsort(times)\n",
    "    sorted_names = [names[i] for i in sorted_indices]\n",
    "    sorted_times = [times[i] for i in sorted_indices]\n",
    "    bars = plt.bar(sorted_names, sorted_times, color=['blue', 'green', 'red', 'purple'])\n",
    "    plt.title('Model Eğitim Süreleri Karşılaştırması', fontsize=14)\n",
    "    plt.ylabel('Süre (saniye)', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{height:.2f}s',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_times_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Eğitim süreleri plotu oluşturulamadı: {str(e)}\")\n",
    "\n",
    "with PdfPages(report_filename) as pdf:\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.text(0.5, 0.8, f\"Model Karşılaştırma Raporu\", \n",
    "                 fontsize=24, ha='center', fontweight='bold')\n",
    "        plt.text(0.5, 0.6, f\"Oluşturulma Tarihi: {datetime.datetime.now().strftime('%d-%m-%Y %H:%M')}\", \n",
    "                 fontsize=16, ha='center')\n",
    "        plt.text(0.5, 0.5, f\"Veri Yüzdesi: %{data_fraction*100:.2f}\", \n",
    "                 fontsize=14, ha='center')\n",
    "        plt.text(0.5, 0.4, f\"LSTM Epoch Sayısı: {epochs}\", \n",
    "                 fontsize=14, ha='center')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"PDF kapak sayfası oluşturulamadı: {str(e)}\")\n",
    "\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        metrics_data = metrics_table.melt(id_vars='Metric', var_name='Model', value_name='Value')\n",
    "        ax = sns.barplot(x='Metric', y='Value', hue='Model', data=metrics_data)\n",
    "        plt.title(\"Model Performans Karşılaştırması\", fontsize=14)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.2f', fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Performans karşılaştırması plotu oluşturulamadı: {str(e)}\")\n",
    "\n",
    "    for img_path, title in [\n",
    "        (\"roc_comparison.png\", \"ROC Eğrisi Karşılaştırması\"),\n",
    "        (\"confusion_matrix_comparison.png\", \"Confusion Matrix Karşılaştırması\"),\n",
    "        (\"tree_models_feature_importance.png\", \"Ağaç Tabanlı Modeller Öznitelik Önemi Karşılaştırması\"),\n",
    "        (\"tsne_plot.png\", \"t-SNE Görselleştirmesi\"),\n",
    "        (\"lstm_anomaly_plot.png\", \"LSTM Anomali Tespiti\"),\n",
    "        (\"mse_histogram.png\", \"MSE Dağılımı ve Anomali Eşiği\"),\n",
    "        (\"training_times_comparison.png\", \"Model Eğitim Süreleri Karşılaştırması\")\n",
    "    ]:\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = plt.imread(img_path)\n",
    "                plt.figure(figsize=(10 if \"confusion_matrix\" not in img_path else 12, 8))\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                plt.title(title)\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"PDF'ye {img_path} eklenemedi: {str(e)}\")\n",
    "\n",
    "    for name in models.keys():\n",
    "        model_name_lower = name.replace(' ', '_').lower()\n",
    "        for img_path, title in [\n",
    "            (f\"shap_summary_{model_name_lower}.png\", f\"SHAP Summary - {name}\"),\n",
    "            (f\"shap_waterfall_{model_name_lower}.png\", f\"SHAP Waterfall - {name}\"),\n",
    "            (f\"shap_force_{model_name_lower}.png\", f\"SHAP Force Plot - {name}\"),\n",
    "            (f\"{model_name_lower}_feature_importance.png\", f\"{name} Öznitelik Önemi\")\n",
    "        ]:\n",
    "            if os.path.exists(img_path):\n",
    "                try:\n",
    "                    img = plt.imread(img_path)\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    plt.imshow(img)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(title)\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"PDF'ye {img_path} eklenemedi: {str(e)}\")\n",
    "\n",
    "    for path, name in zip(\n",
    "        ['learning_curve_random_forest.png', 'learning_curve_catboost.png', 'learning_curve_xgboost.png'],\n",
    "        ['Random Forest', 'CatBoost', 'XGBoost']\n",
    "    ):\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                img = plt.imread(path)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"{name} Öğrenme Eğrisi\")\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"PDF'ye {path} eklenemedi: {str(e)}\")\n",
    "\n",
    "# -------------------- SONUÇ --------------------\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\n✅ İşlem tamamlandı! Toplam süre: {execution_time:.2f} saniye ({execution_time/60:.2f} dakika)\")\n",
    "\n",
    "model_names = list(results.keys())\n",
    "best_model_by_f1 = max(model_names, key=lambda x: results[x]['F1 Score'])\n",
    "best_model_by_auc = max(model_names, key=lambda x: results[x]['AUC'])\n",
    "\n",
    "print(f\"\\n📊 ÖZET BİLGİLER:\")\n",
    "print(f\"☑️ En Yüksek F1 Skoru: {best_model_by_f1} ({results[best_model_by_f1]['F1 Score']:.4f})\")\n",
    "print(f\"☑️ En Yüksek AUC: {best_model_by_auc} ({results[best_model_by_auc]['AUC']:.4f})\")\n",
    "print(f\"☑️ Anomali Eşiği: {threshold:.4f}\")\n",
    "print(f\"☑️ Kullanılan veri yüzdesi: %{data_fraction*100:.2f}\")\n",
    "print(f\"☑️ LSTM epoch sayısı: {epochs}\")\n",
    "\n",
    "try:\n",
    "    if platform.system() == 'Windows':\n",
    "        os.startfile(report_filename)\n",
    "    elif platform.system() == 'Darwin':\n",
    "        subprocess.call(['open', report_filename])\n",
    "    else:\n",
    "        subprocess.call(['xdg-open', report_filename])\n",
    "    print(f\"📁 PDF raporu açıldı: {report_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"PDF açılırken hata: {str(e)}\")\n",
    "    print(f\"Raporun konumu: {os.path.abspath(report_filename)}\")\n",
    "\n",
    "cleanup = messagebox.askyesno(\"Temizleme\", \"Geçici görsel dosyaları silinsin mi?\")\n",
    "if cleanup:\n",
    "    temp_files = [\n",
    "        \"roc_comparison.png\", \"confusion_matrix_comparison.png\",\n",
    "        \"tsne_plot.png\", \"lstm_anomaly_plot.png\", \"mse_histogram.png\",\n",
    "        \"training_times_comparison.png\", \"tree_models_feature_importance.png\"\n",
    "    ]\n",
    "    for name in models.keys():\n",
    "        model_name_lower = name.replace(' ', '_').lower()\n",
    "        temp_files.append(f\"shap_summary_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"shap_waterfall_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"shap_force_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"{model_name_lower}_feature_importance.png\")\n",
    "    for path in ['learning_curve_random_forest.png', 'learning_curve_catboost.png', 'learning_curve_xgboost.png']:\n",
    "        temp_files.append(path)\n",
    "    \n",
    "    for file in temp_files:\n",
    "        if os.path.exists(file):\n",
    "            try:\n",
    "                os.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Dosya silinemedi: {file} - {str(e)}\")\n",
    "    \n",
    "    print(\"🧹 Geçici dosyalar temizlendi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
