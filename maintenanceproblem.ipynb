{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30bf527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri y√ºkleniyor...\n",
      "Veri √∂n i≈üleniyor...\n",
      "Zaman serisi √∂zellikleri ekleniyor...\n",
      "Y√ºksek korelasyonlu √∂zellikler eleniyor...\n",
      "Elenen √∂zellikler: []\n",
      "Kalan √∂zellikler: ['volt', 'rotate', 'pressure', 'vibration', 'volt_lag_1', 'volt_lag_2', 'rotate_lag_1', 'rotate_lag_2', 'pressure_lag_1', 'pressure_lag_2', 'vibration_lag_1', 'vibration_lag_2', 'volt_ma_3', 'rotate_ma_3', 'pressure_ma_3', 'vibration_ma_3', 'volt_std_3', 'rotate_std_3', 'pressure_std_3', 'vibration_std_3', 'volt_diff', 'rotate_diff', 'pressure_diff', 'vibration_diff']\n",
      "Model hazƒ±rlanƒ±yor...\n",
      "SMOTE uygulanƒ±yor... (Veri boyutu: 30000)\n",
      "Logistic Regression, Random Forest, CatBoost ve XGBoost modelleri eƒüitiliyor...\n",
      "\n",
      "‚û°Ô∏è Logistic Regression modeli eƒüitiliyor...\n",
      "üîé Logistic Regression i√ßin SHAP deƒüerleri hesaplanƒ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FEYYAZ\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2b72a6093742a7b734c973b4de4098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHAP ba≈üarƒ±yla tamamlandƒ± - Logistic Regression\n",
      "\n",
      "‚û°Ô∏è Random Forest modeli eƒüitiliyor...\n",
      "üîé Random Forest i√ßin SHAP deƒüerleri hesaplanƒ±yor...\n",
      "‚úÖ SHAP ba≈üarƒ±yla tamamlandƒ± - Random Forest\n",
      "\n",
      "‚û°Ô∏è CatBoost modeli eƒüitiliyor...\n",
      "üîé CatBoost i√ßin SHAP deƒüerleri hesaplanƒ±yor...\n",
      "‚úÖ SHAP ba≈üarƒ±yla tamamlandƒ± - CatBoost\n",
      "\n",
      "‚û°Ô∏è XGBoost modeli eƒüitiliyor...\n",
      "üîé XGBoost i√ßin SHAP deƒüerleri hesaplanƒ±yor...\n",
      "‚úÖ SHAP ba≈üarƒ±yla tamamlandƒ± - XGBoost\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier  \n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import time\n",
    "import datetime\n",
    "import subprocess\n",
    "import platform\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Ba≈ülangƒ±√ß zamanƒ± kaydƒ±\n",
    "start_time = time.time()\n",
    "\n",
    "# -------------------- TKINTER ARAY√úZ√ú --------------------\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "try:\n",
    "    data_fraction = float(simpledialog.askstring(\"Veri Y√ºzdesi\", \"Analiz i√ßin veri y√ºzdesini girin (0.0 - 1.0):\", initialvalue=\"0.015\"))\n",
    "    if not (0 < data_fraction <= 1):\n",
    "        raise ValueError(\"Ge√ßersiz oran\")\n",
    "except:\n",
    "    messagebox.showerror(\"Hata\", \"Ge√ßerli bir oran girilmedi. Program sonlandƒ±rƒ±lƒ±yor.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    epochs = int(simpledialog.askstring(\"Epoch Sayƒ±sƒ±\", \"LSTM Autoencoder i√ßin epoch sayƒ±sƒ±nƒ± girin:\", initialvalue=\"15\"))\n",
    "except:\n",
    "    messagebox.showerror(\"Hata\", \"Ge√ßerli bir epoch sayƒ±sƒ± girilmedi. Program sonlandƒ±rƒ±lƒ±yor.\")\n",
    "    exit()\n",
    "\n",
    "# -------------------- DOSYA YOLLARI --------------------\n",
    "telemetry_path = r\"C:\\Users\\FEYYAZ\\Desktop\\PdM_telemetry.csv\"\n",
    "failures_path = r\"C:\\Users\\FEYYAZ\\Desktop\\PdM_failures.csv\"\n",
    "\n",
    "# Rapor i√ßin benzersiz dosya adƒ± olu≈üturma\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_filename = f\"model_comparison_report_{timestamp}.pdf\"\n",
    "\n",
    "# -------------------- VERƒ∞ Y√úKLEME --------------------\n",
    "print(\"Veri y√ºkleniyor...\")\n",
    "try:\n",
    "    telemetry = pd.read_csv(telemetry_path)\n",
    "    failures = pd.read_csv(failures_path)\n",
    "    telemetry['datetime'] = pd.to_datetime(telemetry['datetime'])\n",
    "    failures['datetime'] = pd.to_datetime(failures['datetime'])\n",
    "except Exception as e:\n",
    "    messagebox.showerror(\"Hata\", f\"Veri dosyalarƒ± y√ºklenemedi: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# -------------------- VERƒ∞ √ñN ƒ∞≈ûLEME --------------------\n",
    "print(\"Veri √∂n i≈üleniyor...\")\n",
    "telemetry_sampled = telemetry.sample(frac=data_fraction, random_state=42)\n",
    "telemetry_hourly = telemetry_sampled.groupby(['machineID', pd.Grouper(key='datetime', freq='h')]).mean().reset_index()\n",
    "telemetry_hourly['failure'] = 0\n",
    "\n",
    "# Ba≈üarƒ±sƒ±zlƒ±klarƒ± i≈üaretleme\n",
    "for _, row in failures.iterrows():\n",
    "    mask = (\n",
    "        (telemetry_hourly['machineID'] == row['machineID']) &\n",
    "        (telemetry_hourly['datetime'] == row['datetime'])\n",
    "    )\n",
    "    telemetry_hourly.loc[mask, 'failure'] = 1\n",
    "\n",
    "# -------------------- ZAMAN SERƒ∞Sƒ∞ √ñZELLƒ∞K M√úHENDƒ∞SLƒ∞ƒûƒ∞ --------------------\n",
    "print(\"Zaman serisi √∂zellikleri ekleniyor...\")\n",
    "def add_time_series_features(df, features, lag_steps=2, window_size=3):\n",
    "    df = df.sort_values(['machineID', 'datetime']).copy()\n",
    "    for feature in features:\n",
    "        for lag in range(1, lag_steps + 1):\n",
    "            df[f'{feature}_lag_{lag}'] = df.groupby('machineID')[feature].shift(lag)\n",
    "        df[f'{feature}_ma_{window_size}'] = df.groupby('machineID')[feature].rolling(window=window_size).mean().reset_index(level=0, drop=True)\n",
    "        df[f'{feature}_std_{window_size}'] = df.groupby('machineID')[feature].rolling(window=window_size).std().reset_index(level=0, drop=True)\n",
    "        df[f'{feature}_diff'] = df.groupby('machineID')[feature].diff()\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "base_features = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "telemetry_hourly = add_time_series_features(telemetry_hourly, base_features, lag_steps=2, window_size=3)\n",
    "\n",
    "# Yeni √∂zellik listesi\n",
    "features = base_features + [\n",
    "    f'{feat}_lag_{lag}' for feat in base_features for lag in range(1, 3)\n",
    "] + [\n",
    "    f'{feat}_ma_3' for feat in base_features\n",
    "] + [\n",
    "    f'{feat}_std_3' for feat in base_features\n",
    "] + [\n",
    "    f'{feat}_diff' for feat in base_features\n",
    "]\n",
    "\n",
    "# -------------------- √ñZELLƒ∞K SE√áƒ∞Mƒ∞ (KORELASYON ANALƒ∞Zƒ∞) --------------------\n",
    "print(\"Y√ºksek korelasyonlu √∂zellikler eleniyor...\")\n",
    "X_temp = telemetry_hourly[features]\n",
    "corr_matrix = X_temp.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "print(f\"Elenen √∂zellikler: {to_drop}\")\n",
    "features = [f for f in features if f not in to_drop]\n",
    "print(f\"Kalan √∂zellikler: {features}\")\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "print(\"Model hazƒ±rlanƒ±yor...\")\n",
    "X = telemetry_hourly[features]\n",
    "y = telemetry_hourly['failure']\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "max_samples = min(len(X_scaled), 30000)\n",
    "X_scaled_limited = X_scaled[:max_samples]\n",
    "y_limited = y[:max_samples]\n",
    "\n",
    "print(f\"SMOTE uygulanƒ±yor... (Veri boyutu: {len(X_scaled_limited)})\")\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled_limited, y_limited)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test, columns=features)\n",
    "\n",
    "# -------------------- D√ñRT MODELƒ∞ DE Eƒûƒ∞TME --------------------\n",
    "print(\"Logistic Regression, Random Forest, CatBoost ve XGBoost modelleri eƒüitiliyor...\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced',\n",
    "        C=0.01,\n",
    "        solver='liblinear'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        min_samples_split=30,\n",
    "        min_samples_leaf=15,\n",
    "        max_features='sqrt',\n",
    "        max_samples=0.7,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=50,\n",
    "        depth=2,\n",
    "        l2_leaf_reg=50,\n",
    "        subsample=0.6,\n",
    "        bagging_temperature=1.5,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=80,\n",
    "        max_depth=2,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.5,\n",
    "        min_child_weight=20,\n",
    "        reg_alpha=2.0,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "shap_values_dict = {}\n",
    "y_pred_dict = {}\n",
    "y_proba_dict = {}\n",
    "xgboost_model = None\n",
    "xgboost_best_iteration = 100\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n‚û°Ô∏è {name} modeli eƒüitiliyor...\")\n",
    "    if name == 'XGBoost':\n",
    "        params = {\n",
    "            'max_depth': 2,\n",
    "            'learning_rate': 0.007,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'min_child_weight': 20,\n",
    "            'reg_lambda': 100,\n",
    "            'reg_alpha': 10.0,\n",
    "            'gamma': 10,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "        evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=300,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=30,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        xgboost_model = bst\n",
    "        xgboost_best_iteration = bst.best_iteration + 1\n",
    "        y_pred = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        y_proba = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    results[name] = {\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "    y_pred_dict[name] = y_pred\n",
    "    y_proba_dict[name] = y_proba\n",
    "    print(f\"üîé {name} i√ßin SHAP deƒüerleri hesaplanƒ±yor...\")\n",
    "    sample_size = min(100, len(X_test_df))\n",
    "    X_test_sample = X_test_df.iloc[:sample_size]\n",
    "    try:\n",
    "        if name == \"XGBoost\":\n",
    "            explainer = shap.TreeExplainer(xgboost_model)\n",
    "            shap_vals = explainer.shap_values(X_test_sample)\n",
    "            shap_values_dict[name] = shap_vals\n",
    "        elif name in [\"Random Forest\", \"CatBoost\"]:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_vals = explainer.shap_values(X_test_sample)\n",
    "            shap_values_dict[name] = shap_vals[1] if isinstance(shap_vals, list) else shap_vals\n",
    "        else:\n",
    "            background = shap.kmeans(X_train, 10)\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, background)\n",
    "            shap_values_dict[name] = explainer.shap_values(X_test_sample)[1]\n",
    "        print(f\"‚úÖ SHAP ba≈üarƒ±yla tamamlandƒ± - {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è SHAP hesaplanamadƒ± - {name}: {str(e)}\")\n",
    "        shap_values_dict[name] = None\n",
    "\n",
    "# -------------------- √ñƒûRENME EƒûRƒ∞Sƒ∞ G√ñRSELƒ∞ --------------------\n",
    "def plot_learning_curve(model, X, y, model_name, cv=5, scoring='f1'):\n",
    "    try:\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    "            train_sizes=np.linspace(0.1, 1.0, 10), shuffle=True, random_state=42\n",
    "        )\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        test_mean = np.mean(test_scores, axis=1)\n",
    "        test_std = np.std(test_scores, axis=1)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_sizes, train_mean, 'o-', color='r', label='Eƒüitim Skoru')\n",
    "        plt.plot(train_sizes, test_mean, 'o-', color='g', label='Doƒürulama Skoru')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\n",
    "        plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\n",
    "        plt.title(f\"{model_name} √ñƒürenme Eƒürisi\")\n",
    "        plt.xlabel(\"Eƒüitim √ñrnek Sayƒ±sƒ±\")\n",
    "        plt.ylabel(\"F1 Skoru\")\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        filename = f\"learning_curve_{model_name.replace(' ', '_').lower()}.png\"\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"√ñƒürenme eƒürisi olu≈üturulamadƒ± - {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "rf_path = plot_learning_curve(models['Random Forest'], X_resampled, y_resampled, \"Random Forest\")\n",
    "cb_path = plot_learning_curve(models['CatBoost'], X_resampled, y_resampled, \"CatBoost\")\n",
    "# For XGBoost, create a temporary XGBClassifier for learning curve\n",
    "xgb_temp = XGBClassifier(\n",
    "  \n",
    "\n",
    ")\n",
    "xgb_path = plot_learning_curve(xgb_temp, X_resampled, y_resampled, \"XGBoost\")\n",
    "print(f\"√ñƒürenme eƒürisi g√∂rselleri olu≈üturuldu:\\n- {rf_path}\\n- {cb_path}\\n- {xgb_path}\")\n",
    "\n",
    "# -------------------- KAR≈ûILA≈ûTIRMA G√ñRSELLE≈ûTƒ∞RMELERƒ∞ --------------------\n",
    "metrics_table = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1 Score', 'AUC'],\n",
    "    'Logistic Regression': [results['Logistic Regression']['Precision'], \n",
    "                          results['Logistic Regression']['Recall'],\n",
    "                          results['Logistic Regression']['F1 Score'],\n",
    "                          results['Logistic Regression']['AUC']],\n",
    "    'Random Forest': [results['Random Forest']['Precision'], \n",
    "                    results['Random Forest']['Recall'],\n",
    "                    results['Random Forest']['F1 Score'],\n",
    "                    results['Random Forest']['AUC']],\n",
    "    'CatBoost': [results['CatBoost']['Precision'], \n",
    "                results['CatBoost']['Recall'],\n",
    "                results['CatBoost']['F1 Score'],\n",
    "                results['CatBoost']['AUC']],\n",
    "    'XGBoost': [results['XGBoost']['Precision'], \n",
    "                results['XGBoost']['Recall'],\n",
    "                results['XGBoost']['F1 Score'],\n",
    "                results['XGBoost']['AUC']]\n",
    "})\n",
    "\n",
    "print(\"\\nüìã Model Performans Kar≈üƒ±la≈ütƒ±rmasƒ±:\")\n",
    "print(metrics_table)\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for name, result in results.items():\n",
    "        plt.plot(result['fpr'], result['tpr'], lw=2, label=f\"{name} (AUC = {result['AUC']:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Eƒürisi Kar≈üƒ±la≈ütƒ±rmasƒ±')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"roc_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"ROC eƒürisi olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for i, (name, y_pred) in enumerate(y_pred_dict.items()):\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "        axes[i].set_title(f'Confusion Matrix - {name}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Confusion matrix olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "for name, shap_values in shap_values_dict.items():\n",
    "    if shap_values is not None:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=features, show=False, plot_size=(8, 5))\n",
    "            plt.title(f\"SHAP Summary - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_summary_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"SHAP summary plot olu≈üturulamadƒ± - {name}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"SHAP summary plot atlandƒ± - {name} i√ßin SHAP deƒüerleri bulunamadƒ±\")\n",
    "\n",
    "for name, shap_values in shap_values_dict.items():\n",
    "    if shap_values is not None:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.plots.waterfall(shap_values[0], max_display=10, show=False)\n",
    "            plt.title(f\"SHAP Waterfall Plot - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_waterfall_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"ƒ∞lk waterfall plot olu≈üturulamadƒ± - {name}: {str(e)}\")\n",
    "            try:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.plots.force(shap_values[0], show=False)\n",
    "                plt.title(f\"SHAP Force Plot - {name}\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"shap_force_{name.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "                plt.close()\n",
    "                print(f\"Alternatif olarak Force Plot olu≈üturuldu - {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Force plot da olu≈üturulamadƒ± - {name}: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, model_name in enumerate(['Random Forest', 'CatBoost', 'XGBoost']):\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        if model_name == 'XGBoost':\n",
    "            # Extract feature importance from Booster\n",
    "            importance = xgboost_model.get_score(importance_type='gain')\n",
    "            feature_names = features  # Use original feature names\n",
    "            importance_values = [importance.get(f, 0) for f in feature_names]\n",
    "            indices = np.argsort(importance_values)[::-1]\n",
    "            sorted_importances = [importance_values[i] for i in indices]\n",
    "            sorted_features = [feature_names[i] for i in indices]\n",
    "        else:\n",
    "            importances = models[model_name].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            sorted_importances = [importances[i] for i in indices]\n",
    "            sorted_features = [features[i] for i in indices]\n",
    "        sns.barplot(x=sorted_importances, y=sorted_features)\n",
    "        plt.title(f\"{model_name} √ñznitelik √ñnemi\")\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(\"tree_models_feature_importance.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"√ñznitelik √∂nemi kar≈üƒ±la≈ütƒ±rmasƒ± olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "for model_name in ['Random Forest', 'CatBoost', 'XGBoost']:\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        if model_name == 'XGBoost':\n",
    "            importance = xgboost_model.get_score(importance_type='gain')\n",
    "            feature_names = features\n",
    "            importance_values = [importance.get(f, 0) for f in feature_names]\n",
    "            indices = np.argsort(importance_values)[::-1]\n",
    "            sorted_importances = [importance_values[i] for i in indices]\n",
    "            sorted_features = [feature_names[i] for i in indices]\n",
    "        else:\n",
    "            importances = models[model_name].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            sorted_importances = [importances[i] for i in indices]\n",
    "            sorted_features = [features[i] for i in indices]\n",
    "        sns.barplot(x=sorted_importances, y=sorted_features)\n",
    "        plt.title(f\"{model_name} √ñznitelik √ñnemi\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{model_name.lower().replace(' ', '_')}_feature_importance.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"√ñznitelik √∂nemi plotu olu≈üturulamadƒ± - {model_name}: {str(e)}\")\n",
    "\n",
    "print(\"t-SNE g√∂rselle≈ütirmesi hazƒ±rlanƒ±yor...\")\n",
    "try:\n",
    "    tsne_size = min(5000, len(X_scaled))\n",
    "    failure_indices = np.where(y[:tsne_size] == 1)[0]\n",
    "    non_failure_indices = np.where(y[:tsne_size] == 0)[0]\n",
    "    min_samples_per_class = min(len(failure_indices), len(non_failure_indices))\n",
    "    replace_sampling = min_samples_per_class < 50\n",
    "    sample_size = max(min(300, min_samples_per_class), 50)\n",
    "    \n",
    "    if len(failure_indices) > 0 and len(non_failure_indices) > 0:\n",
    "        sampled_failure_indices = np.random.choice(\n",
    "            failure_indices, \n",
    "            size=min(sample_size, len(failure_indices)), \n",
    "            replace=replace_sampling\n",
    "        )\n",
    "        sampled_non_failure_indices = np.random.choice(\n",
    "            non_failure_indices, \n",
    "            size=min(sample_size, len(non_failure_indices)), \n",
    "            replace=replace_sampling\n",
    "        )\n",
    "        combined_indices = np.concatenate([sampled_failure_indices, sampled_non_failure_indices])\n",
    "        X_for_tsne = X_scaled[combined_indices]\n",
    "        y_for_tsne = y.iloc[combined_indices]\n",
    "        perplexity_value = min(30, len(X_for_tsne) - 1)\n",
    "        perplexity_value = max(2, perplexity_value)\n",
    "        print(f\"t-SNE kullanƒ±lan √∂rnek sayƒ±sƒ±: {len(X_for_tsne)}, perplexity: {perplexity_value}\")\n",
    "        tsne = TSNE(\n",
    "            n_components=2, \n",
    "            perplexity=perplexity_value,\n",
    "            random_state=42,\n",
    "            learning_rate='auto',  \n",
    "            n_iter=1000\n",
    "        )\n",
    "        X_embedded = tsne.fit_transform(X_for_tsne)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], \n",
    "                          c=y_for_tsne, cmap='coolwarm', \n",
    "                          s=20, \n",
    "                          alpha=0.7)\n",
    "        plt.title(\"t-SNE G√∂rselle≈ütirmesi\", fontsize=14)\n",
    "        plt.xlabel(\"TSNE-1\", fontsize=12)\n",
    "        plt.ylabel(\"TSNE-2\", fontsize=12)\n",
    "        plt.colorbar(scatter, label='Failure')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tsne_plot.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(\"t-SNE g√∂rselle≈ütirmesi ba≈üarƒ±yla olu≈üturuldu.\")\n",
    "    else:\n",
    "        raise ValueError(\"Her iki sƒ±nƒ±ftan da yeterli √∂rnek bulunamadƒ±\")\n",
    "except Exception as e:\n",
    "    print(f\"t-SNE g√∂rselle≈ütirmesi sƒ±rasƒ±nda hata olu≈ütu: {str(e)}\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.text(0.5, 0.5, f\"t-SNE g√∂rselle≈ütirmesi olu≈üturulamadƒ±\\nHata: {str(e)}\", \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"tsne_plot.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------- LSTM AUTOENCODER ANOMALƒ∞ TESPƒ∞Tƒ∞ --------------------\n",
    "print(\"LSTM autoencoder hazƒ±rlanƒ±yor...\")\n",
    "normal_data = telemetry_hourly[telemetry_hourly['failure'] == 0][features].values\n",
    "abnormal_data = telemetry_hourly[telemetry_hourly['failure'] == 1][features].values\n",
    "max_normal = min(8000, len(normal_data))\n",
    "normal_data = normal_data[:max_normal]\n",
    "scaler_lstm = MinMaxScaler()\n",
    "normal_scaled = scaler_lstm.fit_transform(normal_data)\n",
    "seq_length = 10\n",
    "X_seq = []\n",
    "for i in range(len(normal_scaled) - seq_length):\n",
    "    X_seq.append(normal_scaled[i:i+seq_length])\n",
    "X_seq = np.array(X_seq)\n",
    "print(f\"LSTM autoencoder eƒüitiliyor... (Epochs: {epochs})\")\n",
    "input_layer = Input(shape=(seq_length, X_seq.shape[2]))\n",
    "x = LSTM(8, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(4, activation='relu', return_sequences=False, kernel_regularizer=l2(0.01))(x)\n",
    "x = RepeatVector(seq_length)(x)\n",
    "x = LSTM(4, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(8, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "output_layer = TimeDistributed(Dense(X_seq.shape[2]))(x)\n",
    "model_lstm = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "history = model_lstm.fit(\n",
    "    X_seq, X_seq, \n",
    "    epochs=epochs, \n",
    "    batch_size=64, \n",
    "    validation_split=0.1, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "X_pred = model_lstm.predict(X_seq)\n",
    "mse = np.mean(np.power(X_seq - X_pred, 2), axis=(1, 2))\n",
    "threshold = np.percentile(mse, 95)\n",
    "print(\"üî∫ Anomali e≈üik deƒüeri:\", threshold)\n",
    "try:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(mse, label='Reconstruction Error')\n",
    "    plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "    plt.title(\"LSTM Autoencoder Anomali Tespiti\", fontsize=14)\n",
    "    plt.xlabel(\"Dizi ƒ∞ndeksi\", fontsize=12)\n",
    "    plt.ylabel(\"Hata (MSE)\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"LSTM Autoencoder Eƒüitim Ge√ßmi≈üi\", fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"lstm_anomaly_plot.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"LSTM anomali plotu olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(mse, bins=50, alpha=0.7, color='blue')\n",
    "    plt.axvline(x=threshold, color='red', linestyle='--', \n",
    "                label=f'Anomali E≈üiƒüi ({threshold:.4f})')\n",
    "    plt.title(\"MSE Daƒüƒ±lƒ±mƒ± ve Anomali E≈üiƒüi\", fontsize=14)\n",
    "    plt.xlabel(\"MSE Deƒüeri\", fontsize=12)\n",
    "    plt.ylabel(\"Frekans\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mse_histogram.png\", dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"MSE histogramƒ± olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "# -------------------- PDF RAPORU --------------------\n",
    "print(f\"üìÑ PDF raporu olu≈üturuluyor: {report_filename}\")\n",
    "training_times = {}\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    if name == 'XGBoost':\n",
    "        # Use xgboost.train for training time measurement\n",
    "        params = {\n",
    "            'max_depth': 3,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'min_child_weight': 5,\n",
    "            'reg_lambda': 30,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42\n",
    "        }\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "        evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=500,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    training_times[name] = end - start\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    names = list(training_times.keys())\n",
    "    times = list(training_times.values())\n",
    "    sorted_indices = np.argsort(times)\n",
    "    sorted_names = [names[i] for i in sorted_indices]\n",
    "    sorted_times = [times[i] for i in sorted_indices]\n",
    "    bars = plt.bar(sorted_names, sorted_times, color=['blue', 'green', 'red', 'purple'])\n",
    "    plt.title('Model Eƒüitim S√ºreleri Kar≈üƒ±la≈ütƒ±rmasƒ±', fontsize=14)\n",
    "    plt.ylabel('S√ºre (saniye)', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{height:.2f}s',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_times_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Eƒüitim s√ºreleri plotu olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "with PdfPages(report_filename) as pdf:\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.text(0.5, 0.8, f\"Model Kar≈üƒ±la≈ütƒ±rma Raporu\", \n",
    "                 fontsize=24, ha='center', fontweight='bold')\n",
    "        plt.text(0.5, 0.6, f\"Olu≈üturulma Tarihi: {datetime.datetime.now().strftime('%d-%m-%Y %H:%M')}\", \n",
    "                 fontsize=16, ha='center')\n",
    "        plt.text(0.5, 0.5, f\"Veri Y√ºzdesi: %{data_fraction*100:.2f}\", \n",
    "                 fontsize=14, ha='center')\n",
    "        plt.text(0.5, 0.4, f\"LSTM Epoch Sayƒ±sƒ±: {epochs}\", \n",
    "                 fontsize=14, ha='center')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"PDF kapak sayfasƒ± olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        metrics_data = metrics_table.melt(id_vars='Metric', var_name='Model', value_name='Value')\n",
    "        ax = sns.barplot(x='Metric', y='Value', hue='Model', data=metrics_data)\n",
    "        plt.title(\"Model Performans Kar≈üƒ±la≈ütƒ±rmasƒ±\", fontsize=14)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.2f', fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Performans kar≈üƒ±la≈ütƒ±rmasƒ± plotu olu≈üturulamadƒ±: {str(e)}\")\n",
    "\n",
    "    for img_path, title in [\n",
    "        (\"roc_comparison.png\", \"ROC Eƒürisi Kar≈üƒ±la≈ütƒ±rmasƒ±\"),\n",
    "        (\"confusion_matrix_comparison.png\", \"Confusion Matrix Kar≈üƒ±la≈ütƒ±rmasƒ±\"),\n",
    "        (\"tree_models_feature_importance.png\", \"Aƒüa√ß Tabanlƒ± Modeller √ñznitelik √ñnemi Kar≈üƒ±la≈ütƒ±rmasƒ±\"),\n",
    "        (\"tsne_plot.png\", \"t-SNE G√∂rselle≈ütirmesi\"),\n",
    "        (\"lstm_anomaly_plot.png\", \"LSTM Anomali Tespiti\"),\n",
    "        (\"mse_histogram.png\", \"MSE Daƒüƒ±lƒ±mƒ± ve Anomali E≈üiƒüi\"),\n",
    "        (\"training_times_comparison.png\", \"Model Eƒüitim S√ºreleri Kar≈üƒ±la≈ütƒ±rmasƒ±\")\n",
    "    ]:\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = plt.imread(img_path)\n",
    "                plt.figure(figsize=(10 if \"confusion_matrix\" not in img_path else 12, 8))\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                plt.title(title)\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"PDF'ye {img_path} eklenemedi: {str(e)}\")\n",
    "\n",
    "    for name in models.keys():\n",
    "        model_name_lower = name.replace(' ', '_').lower()\n",
    "        for img_path, title in [\n",
    "            (f\"shap_summary_{model_name_lower}.png\", f\"SHAP Summary - {name}\"),\n",
    "            (f\"shap_waterfall_{model_name_lower}.png\", f\"SHAP Waterfall - {name}\"),\n",
    "            (f\"shap_force_{model_name_lower}.png\", f\"SHAP Force Plot - {name}\"),\n",
    "            (f\"{model_name_lower}_feature_importance.png\", f\"{name} √ñznitelik √ñnemi\")\n",
    "        ]:\n",
    "            if os.path.exists(img_path):\n",
    "                try:\n",
    "                    img = plt.imread(img_path)\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    plt.imshow(img)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(title)\n",
    "                    pdf.savefig()\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"PDF'ye {img_path} eklenemedi: {str(e)}\")\n",
    "\n",
    "    for path, name in zip(\n",
    "        ['learning_curve_random_forest.png', 'learning_curve_catboost.png', 'learning_curve_xgboost.png'],\n",
    "        ['Random Forest', 'CatBoost', 'XGBoost']\n",
    "    ):\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                img = plt.imread(path)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"{name} √ñƒürenme Eƒürisi\")\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"PDF'ye {path} eklenemedi: {str(e)}\")\n",
    "\n",
    "# -------------------- SONU√á --------------------\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\n‚úÖ ƒ∞≈ülem tamamlandƒ±! Toplam s√ºre: {execution_time:.2f} saniye ({execution_time/60:.2f} dakika)\")\n",
    "\n",
    "model_names = list(results.keys())\n",
    "best_model_by_f1 = max(model_names, key=lambda x: results[x]['F1 Score'])\n",
    "best_model_by_auc = max(model_names, key=lambda x: results[x]['AUC'])\n",
    "\n",
    "print(f\"\\nüìä √ñZET Bƒ∞LGƒ∞LER:\")\n",
    "print(f\"‚òëÔ∏è En Y√ºksek F1 Skoru: {best_model_by_f1} ({results[best_model_by_f1]['F1 Score']:.4f})\")\n",
    "print(f\"‚òëÔ∏è En Y√ºksek AUC: {best_model_by_auc} ({results[best_model_by_auc]['AUC']:.4f})\")\n",
    "print(f\"‚òëÔ∏è Anomali E≈üiƒüi: {threshold:.4f}\")\n",
    "print(f\"‚òëÔ∏è Kullanƒ±lan veri y√ºzdesi: %{data_fraction*100:.2f}\")\n",
    "print(f\"‚òëÔ∏è LSTM epoch sayƒ±sƒ±: {epochs}\")\n",
    "\n",
    "try:\n",
    "    if platform.system() == 'Windows':\n",
    "        os.startfile(report_filename)\n",
    "    elif platform.system() == 'Darwin':\n",
    "        subprocess.call(['open', report_filename])\n",
    "    else:\n",
    "        subprocess.call(['xdg-open', report_filename])\n",
    "    print(f\"üìÅ PDF raporu a√ßƒ±ldƒ±: {report_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"PDF a√ßƒ±lƒ±rken hata: {str(e)}\")\n",
    "    print(f\"Raporun konumu: {os.path.abspath(report_filename)}\")\n",
    "\n",
    "cleanup = messagebox.askyesno(\"Temizleme\", \"Ge√ßici g√∂rsel dosyalarƒ± silinsin mi?\")\n",
    "if cleanup:\n",
    "    temp_files = [\n",
    "        \"roc_comparison.png\", \"confusion_matrix_comparison.png\",\n",
    "        \"tsne_plot.png\", \"lstm_anomaly_plot.png\", \"mse_histogram.png\",\n",
    "        \"training_times_comparison.png\", \"tree_models_feature_importance.png\"\n",
    "    ]\n",
    "    for name in models.keys():\n",
    "        model_name_lower = name.replace(' ', '_').lower()\n",
    "        temp_files.append(f\"shap_summary_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"shap_waterfall_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"shap_force_{model_name_lower}.png\")\n",
    "        temp_files.append(f\"{model_name_lower}_feature_importance.png\")\n",
    "    for path in ['learning_curve_random_forest.png', 'learning_curve_catboost.png', 'learning_curve_xgboost.png']:\n",
    "        temp_files.append(path)\n",
    "    \n",
    "    for file in temp_files:\n",
    "        if os.path.exists(file):\n",
    "            try:\n",
    "                os.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Dosya silinemedi: {file} - {str(e)}\")\n",
    "    \n",
    "    print(\"üßπ Ge√ßici dosyalar temizlendi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
